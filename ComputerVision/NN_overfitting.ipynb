{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOI33r/2ToBOUrApPVrRHco",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantiyaramareddy/AI-ML-Learnings/blob/master/ComputerVision/NN_overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kkGvXSAQOxti"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sweep config for selecting experiment\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
        "    'parameters': {\n",
        "        'batch_size':{'values': [8]},\n",
        "        'learning_rate': {'values': [1e-3]},\n",
        "        'hidden_nodes':{'values':[128]},\n",
        "        'img_size':{'values':[16]},\n",
        "        'epochs':{'values':[10]},\n",
        "        'experiment':{'values':['dropout_only','batchnorm_only','full']}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"5_flowers_experiments\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUoC83V3ef-W",
        "outputId": "19efb140-2a91-47a1-db1e-73ee4bb8fc39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: gy9otly7\n",
            "Sweep URL: https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  with wandb.init() as run:\n",
        "    config = wandb.config\n",
        "\n",
        "    IMG_HEIGHT = config.img_size\n",
        "    IMG_WIDTH = config.img_size\n",
        "    IMG_CHANNELS = 3\n",
        "    CLASS_NAMES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "    def read_and_decode(filename, resize_dims):\n",
        "      img_bytes = tf.io.read_file(filename)\n",
        "      img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
        "      img = tf.image.resize(img, resize_dims)\n",
        "      return img\n",
        "\n",
        "    def parse_csvline(csv_line):\n",
        "      record_default = [\"\",\"\"]\n",
        "      filename, label_string = tf.io.decode_csv(csv_line, record_defaults=record_default)\n",
        "      img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
        "      label = tf.where(tf.equal(CLASS_NAMES, label_string))[0][0]\n",
        "      return img, label\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = (\n",
        "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/train_set.csv\")\n",
        "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(config.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    eval_dataset = (\n",
        "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\")\n",
        "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(config.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    # Build Model\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "\n",
        "    if config.experiment == 'dropout_only':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes, activation='relu'))\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    elif config.experiment == 'batchnorm_only':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes, activation='relu'))\n",
        "      model.add(keras.layers.BatchNormalization())\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    elif config.experiment == 'full':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes,\n",
        "                                   kernal_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   use_bias=False))\n",
        "      model.add(keras.layers.BatchNormalization())\n",
        "      model.add(keras.layers.Activation('relu'))\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(keras.layers.Dense(len(CLASS_NAMES), activation='softmax'))\n",
        "\n",
        "    #Compile\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=False\n",
        "        ),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    callbacks = [WandbMetricsLogger(log_freq=5)]\n",
        "    if config.experiment == 'full':\n",
        "      callbacks.append(keras.callbacks.EarlyStopping\n",
        "                       (monitor='val_loss', patience=3, restore_best_weights=True))\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=config.epochs,\n",
        "        validation_data=eval_dataset,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "wandb.agent(sweep_id, train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWM5EXL-gN4P",
        "outputId": "56107f69-d888-4817-c8d1-2179066f32a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: poixrja9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \texperiment: dropout_only\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_nodes: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timg_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprashantiyaramareddy7\u001b[0m (\u001b[33mprashantiyaramareddy7-nit-rourkela\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260108_030756-poixrja9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/poixrja9' target=\"_blank\">silver-sweep-1</a></strong> to <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/poixrja9' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/poixrja9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    413/Unknown \u001b[1m189s\u001b[0m 450ms/step - accuracy: 0.2191 - loss: 51.4782"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 500ms/step - accuracy: 0.2192 - loss: 51.3909 - val_accuracy: 0.2378 - val_loss: 1.8246\n",
            "Epoch 2/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 391ms/step - accuracy: 0.2429 - loss: 1.7060 - val_accuracy: 0.2378 - val_loss: 1.7485\n",
            "Epoch 3/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 340ms/step - accuracy: 0.2460 - loss: 1.6216 - val_accuracy: 0.2378 - val_loss: 1.7078\n",
            "Epoch 4/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 269ms/step - accuracy: 0.2402 - loss: 1.6196 - val_accuracy: 0.2324 - val_loss: 1.7109\n",
            "Epoch 5/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 256ms/step - accuracy: 0.2436 - loss: 1.6011 - val_accuracy: 0.2351 - val_loss: 1.7280\n",
            "Epoch 6/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 247ms/step - accuracy: 0.2430 - loss: 1.6275 - val_accuracy: 0.2351 - val_loss: 1.7194\n",
            "Epoch 7/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 245ms/step - accuracy: 0.2446 - loss: 1.5912 - val_accuracy: 0.2351 - val_loss: 1.7189\n",
            "Epoch 8/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 246ms/step - accuracy: 0.2444 - loss: 1.5941 - val_accuracy: 0.2351 - val_loss: 1.7176\n",
            "Epoch 9/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 233ms/step - accuracy: 0.2464 - loss: 1.5988 - val_accuracy: 0.2351 - val_loss: 1.6894\n",
            "Epoch 10/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 233ms/step - accuracy: 0.2453 - loss: 1.5899 - val_accuracy: 0.2351 - val_loss: 1.6906\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▂▂▄▃▃▆██▅▁▃▄▃▆▅▆▆▄▆▇▆▄▆▆▅▅▆▆▅▄▆▆▇▇▃▆▆▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▇▇█▇▇▇█▇</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>███▁▅▅▅▅▅▅</td></tr><tr><td>epoch/val_loss</td><td>█▄▂▂▃▃▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.25</td></tr><tr><td>batch/batch_step</td><td>4145</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>1.59067</td></tr><tr><td>epoch/accuracy</td><td>0.2503</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>1.59072</td></tr><tr><td>epoch/val_accuracy</td><td>0.23514</td></tr><tr><td>epoch/val_loss</td><td>1.69055</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silver-sweep-1</strong> at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/poixrja9' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/poixrja9</a><br> View project at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260108_030756-poixrja9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8g12dvvz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \texperiment: batchnorm_only\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_nodes: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timg_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260108_032835-8g12dvvz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/8g12dvvz' target=\"_blank\">deep-sweep-2</a></strong> to <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/8g12dvvz' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/8g12dvvz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 232ms/step - accuracy: 0.3146 - loss: 1.7198 - val_accuracy: 0.4270 - val_loss: 1.5801\n",
            "Epoch 2/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 231ms/step - accuracy: 0.4327 - loss: 1.3539 - val_accuracy: 0.4297 - val_loss: 1.7972\n",
            "Epoch 3/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 228ms/step - accuracy: 0.4447 - loss: 1.3211 - val_accuracy: 0.4297 - val_loss: 1.8266\n",
            "Epoch 4/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 219ms/step - accuracy: 0.4458 - loss: 1.2964 - val_accuracy: 0.4459 - val_loss: 1.8379\n",
            "Epoch 5/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 237ms/step - accuracy: 0.4736 - loss: 1.2779 - val_accuracy: 0.4703 - val_loss: 1.8705\n",
            "Epoch 6/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 216ms/step - accuracy: 0.4641 - loss: 1.2628 - val_accuracy: 0.4649 - val_loss: 1.9351\n",
            "Epoch 7/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 225ms/step - accuracy: 0.4687 - loss: 1.2591 - val_accuracy: 0.4730 - val_loss: 2.1306\n",
            "Epoch 8/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 221ms/step - accuracy: 0.4495 - loss: 1.2849 - val_accuracy: 0.4351 - val_loss: 2.1047\n",
            "Epoch 9/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 219ms/step - accuracy: 0.4543 - loss: 1.2855 - val_accuracy: 0.4432 - val_loss: 2.1047\n",
            "Epoch 10/10\n",
            "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 227ms/step - accuracy: 0.4663 - loss: 1.2773 - val_accuracy: 0.4405 - val_loss: 2.1302\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>▁▁▂▃▄▇▆▇▆▆▇▇▇▇▇▇▇████▇██▇▇▇███▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▇▇▇▇████</td></tr><tr><td>batch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/loss</td><td>█▆▅▅▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>epoch/accuracy</td><td>▁▅▆▆█▇▇▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>epoch/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▁▁▁▄█▇█▂▃▃</td></tr><tr><td>epoch/val_loss</td><td>▁▄▄▄▅▆████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch/accuracy</td><td>0.46229</td></tr><tr><td>batch/batch_step</td><td>4145</td></tr><tr><td>batch/learning_rate</td><td>0.001</td></tr><tr><td>batch/loss</td><td>1.28957</td></tr><tr><td>epoch/accuracy</td><td>0.46212</td></tr><tr><td>epoch/epoch</td><td>9</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>1.29005</td></tr><tr><td>epoch/val_accuracy</td><td>0.44054</td></tr><tr><td>epoch/val_loss</td><td>2.13023</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">deep-sweep-2</strong> at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/8g12dvvz' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/8g12dvvz</a><br> View project at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260108_032835-8g12dvvz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vqgxbt1y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \texperiment: full\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_nodes: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timg_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260108_034551-vqgxbt1y</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/vqgxbt1y' target=\"_blank\">crimson-sweep-3</a></strong> to <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/gy9otly7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/vqgxbt1y' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/vqgxbt1y</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2017578586.py\", line 52, in train\n",
            "    model.add(keras.layers.Dense(config.hidden_nodes,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py\", line 93, in __init__\n",
            "    super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Unrecognized keyword arguments passed to Dense: {'kernal_regularizer': <keras.src.regularizers.regularizers.L2 object at 0x7ec2905278c0>}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crimson-sweep-3</strong> at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/vqgxbt1y' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/vqgxbt1y</a><br> View project at: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260108_034551-vqgxbt1y/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/wandb/agents/pyagent.py\", line 296, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipython-input-2017578586.py\", line 52, in train\n",
            "    model.add(keras.layers.Dense(config.hidden_nodes,\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py\", line 93, in __init__\n",
            "    super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 291, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Unrecognized keyword arguments passed to Dense: {'kernal_regularizer': <keras.src.regularizers.regularizers.L2 object at 0x7ec2905278c0>}\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run vqgxbt1y errored: Unrecognized keyword arguments passed to Dense: {'kernal_regularizer': <keras.src.regularizers.regularizers.L2 object at 0x7ec2905278c0>}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ]
    }
  ]
}