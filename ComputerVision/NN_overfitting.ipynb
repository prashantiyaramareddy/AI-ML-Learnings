{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI33r/2ToBOUrApPVrRHco",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantiyaramareddy/AI-ML-Learnings/blob/master/ComputerVision/NN_overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kkGvXSAQOxti"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sweep config for selecting experiment\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
        "    'parameters': {\n",
        "        'batch_size':{'values': [8]},\n",
        "        'learning_rate': {'values': [1e-3]},\n",
        "        'hidden_nodes':{'values':[128]},\n",
        "        'img_size':{'values':[16]},\n",
        "        'epochs':{'values':[10]},\n",
        "        'experiment':{'values':['dropout_only','batchnorm_only','full']}\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"5_flowers_experiments\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUoC83V3ef-W",
        "outputId": "a639f71d-1348-4a53-d813-ca4939025745"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: bviizi38\n",
            "Sweep URL: https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/bviizi38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  with wandb.init() as run:\n",
        "    config = wandb.config\n",
        "\n",
        "    IMG_HEIGHT = config.img_size\n",
        "    IMG_WIDTH = config.img_size\n",
        "    IMG_CHANNELS = 3\n",
        "    CLASS_NAMES = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "\n",
        "    def read_and_decode(filename, resize_dims):\n",
        "      img_bytes = tf.io.read_file(filename)\n",
        "      img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
        "      img = tf.image.resize(img, resize_dims)\n",
        "      return img\n",
        "\n",
        "    def parse_csvline(csv_line):\n",
        "      record_default = [\"\",\"\"]\n",
        "      filename, label_string = tf.io.decode_csv(csv_line, record_defaults=record_default)\n",
        "      img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
        "      label = tf.where(tf.equal(CLASS_NAMES, label_string))[0][0]\n",
        "      return img, label\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = (\n",
        "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/train_set.csv\")\n",
        "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(config.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    eval_dataset = (\n",
        "        tf.data.TextLineDataset(\"gs://cloud-ml-data/img/flower_photos/eval_set.csv\")\n",
        "        .map(parse_csvline, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .batch(config.batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    # Build Model\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "\n",
        "    if config.experiment == 'dropout_only':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes, activation='relu'))\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    elif config.experiment == 'batchnorm_only':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes, activation='relu'))\n",
        "      model.add(keras.layers.BatchNormalization())\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    elif config.experiment == 'full':\n",
        "      model.add(keras.layers.Dense(config.hidden_nodes,\n",
        "                                   kernal_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   use_bias=False))\n",
        "      model.add(keras.layers.BatchNormalization())\n",
        "      model.add(keras.layers.Activation('relu'))\n",
        "      model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "    model.add(keras.layers.Dense(len(CLASS_NAMES), activation='softmax'))\n",
        "\n",
        "    #Compile\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=False\n",
        "        ),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    callbacks = [WandbMetricsLogger(log_freq=5)]\n",
        "    if config.experiment == 'full':\n",
        "      callbacks.append(keras.callbacks.EarlyStopping\n",
        "                       (monitor='val_loss', patience=3, restore_best_weights=True))\n",
        "\n",
        "    # Train\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=config.epochs,\n",
        "        validation_data=eval_dataset,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "wandb.agent(sweep_id, train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "iWM5EXL-gN4P",
        "outputId": "92c2e47f-ea79-4c41-db8d-70b23a9abd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3gefe5mj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \texperiment: dropout_only\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_nodes: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timg_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mprashantiyaramareddy7\u001b[0m (\u001b[33mprashantiyaramareddy7-nit-rourkela\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260107_083135-3gefe5mj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/3gefe5mj' target=\"_blank\">olive-sweep-1</a></strong> to <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/bviizi38' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/bviizi38</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/bviizi38' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/sweeps/bviizi38</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/3gefe5mj' target=\"_blank\">https://wandb.ai/prashantiyaramareddy7-nit-rourkela/5_flowers_experiments/runs/3gefe5mj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    413/Unknown \u001b[1m153s\u001b[0m 366ms/step - accuracy: 0.2323 - loss: 48.9616"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 408ms/step - accuracy: 0.2323 - loss: 48.8791 - val_accuracy: 0.2405 - val_loss: 1.8669\n",
            "Epoch 2/10\n",
            "\u001b[1m298/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 333ms/step - accuracy: 0.2387 - loss: 1.8057"
          ]
        }
      ]
    }
  ]
}