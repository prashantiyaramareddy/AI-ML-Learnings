{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9N81SnUZhQe9wiDsR8B3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantiyaramareddy/AI-ML-Learnings/blob/master/ComputerVision/VGGNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG-Net Implementation"
      ],
      "metadata": {
        "id": "rxmRmyfkYy-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGGNet is a convolutional neural network architecture proposed by the Visual Geometry Group (VGG) from Oxford University. It is known for its simplicity and uniform architecture, using small convolutional filters and deep layers."
      ],
      "metadata": {
        "id": "w4EF-T6xY5t7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKDX4KpyYMWT"
      },
      "outputs": [],
      "source": [
        "### Import Required Libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "NF7O_ZCiEb4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU Availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "5QZbCSXFdz8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define transforms to be applied on dataset"
      ],
      "metadata": {
        "id": "4xPSmXU_EvNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import padding\n",
        "\n",
        "# Use the mean and sta from CIFAR10\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "train_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomCrop(32, padding=4),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = torchvision.transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean, std)\n",
        "])\n"
      ],
      "metadata": {
        "id": "5jlN-GxLE0hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n"
      ],
      "metadata": {
        "id": "H9dyQEFEFYbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "val_size = 5000\n",
        "train_size = len(train_dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "9xc8AomIFjTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(test_loader), len(val_loader)"
      ],
      "metadata": {
        "id": "dqDe1JeRdMwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Load Pretrained Model\n",
        "vggnet = models.vgg19(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in vggnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the last fully connected layer\n",
        "num_classes = 10\n",
        "vggnet.classifier[6] = nn.Linear(4096, num_classes)\n",
        "\n",
        "# Only the new final layer should be trainable\n",
        "for param in vggnet.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "vggnet = vggnet.to(device)"
      ],
      "metadata": {
        "id": "U5Rv4lqmdQUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vggnet.parameters(), lr=0.001,\n",
        "                       weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "model = vggnet"
      ],
      "metadata": {
        "id": "jDXNFa6sd7yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_EpochLoss = 0\n",
        "  for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_EpochLoss += loss.item()\n",
        "\n",
        "avg_loss = total_EpochLoss / len(train_loader)\n",
        "print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "val_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "avg_val_loss = val_loss / len(val_loader)\n",
        "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "print(f\"Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "#Step the scheduler with validation loss\n",
        "scheduler.step(avg_val_loss)\n",
        "\n",
        "# Save the checkpoint every 10 epochs\n",
        "if (epoch + 1) % 10 == 0:\n",
        "  checkpoint_path = f'checkpoint_epoch_{epoch + 1}.pth'\n",
        "  torch.save({\n",
        "      'epoch': epoch + 1,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'loss': avg_loss,\n",
        "  }, checkpoint_path)\n",
        "  print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IqyD14GxePBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "ZIpG6K43prIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation in test dataset"
      ],
      "metadata": {
        "id": "_l-XIarepslp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batchFeatures, batchLabels in test_loader:\n",
        "    # move to gpu\n",
        "    batchFeatures, batchLabels = batchFeatures.to(device), batchLabels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(batchFeatures)\n",
        "\n",
        "    # Calculate Loss\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += batchLabels.size(0)\n",
        "    correct += (predicted == batchLabels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "B5qh2vEzpwWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "tIOLqWTkp0Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from random import sample\n",
        "\n",
        "# Define CIFAR-10 class names\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradients for prediction\n",
        "with torch.no_grad():\n",
        "  for batchFeatures, batchLabels in test_loader:\n",
        "    # Move to GPU\n",
        "    batchFeatures, batchLabels = batchFeatures.to(device), batchLabels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(batchFeatures)\n",
        "\n",
        "    _, predicted_indices = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Select N random images\n",
        "    N = 5\n",
        "    indices = sample(range(len(batchFeatures)), N)\n",
        "\n",
        "    # Plot the images using the axes object\n",
        "    fig, axes = plt.subplots(1, N, figsize=(15, 5))\n",
        "\n",
        "    # Plot images with actual and predicted labels\n",
        "    for i in range(N):\n",
        "      idx = indices[i]\n",
        "\n",
        "      # Get image, label and predicted labels\n",
        "      img = batchFeatures[idx].cpu()\n",
        "      actual = classes[batchLabels[idx].item()]\n",
        "      predicted_label = classes[predicted_indices[idx].item()]\n",
        "\n",
        "      # Denormalize image for diaplay\n",
        "      img = img * torch.tensor(std).view(3, 1, 1) + torch.tensor(mean).view(3, 1, 1)\n",
        "      img = img.permute(1,2,0)\n",
        "      img = torch.clamp(img, 0, 1)\n",
        "\n",
        "      # Plot image on the respective subplot axis\n",
        "      axes[i].imshow(img)\n",
        "      axes[i].set_title(f\"Actual: {actual}\\nPredicted: {predicted_label}\")\n",
        "      axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "KVYkjBBrp2k5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}